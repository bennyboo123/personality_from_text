{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup\n",
    "We start off by importing the Python libraries we need. We also import the `essays` dataset (`essays.csv`) that we can find in the `data` directory of our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BiegT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "essays_raw = pd.read_csv('data/essays.csv', engine='python');\n",
    "\n",
    "def clean_colnames(df):\n",
    "    df.columns = df.columns.str.replace(\"c|#\", \"\").str.lower()\n",
    "    return df\n",
    "    \n",
    "essays_raw = clean_colnames(essays_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inpect the data\n",
    "\n",
    "Let's take a quick look at the structure of the `essays` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            authid                                               text ext neu  \\\n",
      "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...   n   y   \n",
      "1  1997_605191.txt  Well, here we go with the stream of consciousn...   n   n   \n",
      "2  1997_687252.txt  An open keyboard and buttons to push. The thin...   n   y   \n",
      "3  1997_568848.txt  I can't believe it!  It's really happening!  M...   y   n   \n",
      "4  1997_688160.txt  Well, here I go with the good old stream of co...   y   n   \n",
      "\n",
      "  agr con opn  \n",
      "0   y   n   y  \n",
      "1   y   n   n  \n",
      "2   n   y   y  \n",
      "3   y   y   n  \n",
      "4   y   n   y  \n",
      "\n",
      "Number of rows and columns: (2467, 7) \n",
      "\n",
      "All author ids are unique!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "authid    0\n",
       "text      0\n",
       "ext       0\n",
       "neu       0\n",
       "agr       0\n",
       "con       0\n",
       "opn       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first few rows of the dataset\n",
    "print(essays_raw.head())\n",
    "\n",
    "# Print the number of rows and colums\n",
    "print(\"\\nNumber of rows and columns: {} \\n\".format(essays_raw.shape))\n",
    "\n",
    "# Check if author ids are unique\n",
    "if len(essays_raw['authid']) == len(essays_raw):\n",
    "    print('All author ids are unique!')\n",
    "else:\n",
    "    print('Author ids are not unique!')\n",
    "    \n",
    "# Check if there are missing values in the dataset:\n",
    "essays_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a datasset containing 2467 essays from the same number of individual authors. We can also see that the dataset does not contain any missing values. Each essay is associated with an author id and 5 binary labels (one label per personality dimension):\n",
    "\n",
    "* Extraversion (`ext`)\n",
    "* Neuroticism (`neu`)\n",
    "* Agreeableness (`agr`)\n",
    "* Conscientiousness (`con`)\n",
    "* Openess (`opn`)\n",
    "\n",
    "Note that in psychological theory, the Big Five model actually considers all five traits as independent continious dimensions (and even defines sub dimensions - so-called facets - for each of them). However, for this machine learning task, the labels in our datasets represent just binary categories (e.g. a value of `y` in the `neu`-column indicates that the author of the given essay is neurotic).\n",
    "\n",
    "Obviously, our goal is to predict the five binary labels for a given essay. In the other words, the task at hand is a binary multi label classification task. Before we create a train-test split and preprocess our data, let's explore it a little bit further. For example we can look at the distribution of labels for each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>dimension</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "      <td>ext</td>\n",
       "      <td>1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y</td>\n",
       "      <td>ext</td>\n",
       "      <td>1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n</td>\n",
       "      <td>neu</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y</td>\n",
       "      <td>neu</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>agr</td>\n",
       "      <td>1157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>y</td>\n",
       "      <td>agr</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n</td>\n",
       "      <td>con</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>y</td>\n",
       "      <td>con</td>\n",
       "      <td>1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n</td>\n",
       "      <td>opn</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>y</td>\n",
       "      <td>opn</td>\n",
       "      <td>1271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label dimension  count\n",
       "0     n       ext   1191\n",
       "1     y       ext   1276\n",
       "2     n       neu   1234\n",
       "3     y       neu   1233\n",
       "4     n       agr   1157\n",
       "5     y       agr   1310\n",
       "6     n       con   1214\n",
       "7     y       con   1253\n",
       "8     n       opn   1196\n",
       "9     y       opn   1271"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = pd.melt(essays_raw.iloc[:, 2:7].apply(pd.Series.value_counts).reset_index().copy(),\n",
    "                       id_vars = ['index'], var_name = 'dimension', value_name = 'count').rename(columns = {'index': 'label'})\n",
    "\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x128f93d4320>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = \"dimension\", y = \"count\", hue = \"label\", data = label_counts)\n",
    "plt.legend(loc = 'center right')\n",
    "plt.legend(bbox_to_anchor = (1.05, 1), loc = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot we can see that for each dimension the number of samples on the positive class (`y`) is roughly equal to the number of samples of the negative class (`n`). In other words, our dataset is appears to be pretty balanced (at least, if you look at each dimension separatly) Let's also look at the counts of individual combinations of dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indiv_combs = (essays_raw['ext'] + essays_raw['neu'] + essays_raw['agr'] + essays_raw['con'] + essays_raw['opn']). \\\n",
    "               value_counts()\n",
    "\n",
    "indiv_combs.plot(kind = \"bar\", color = \"lightblue\")\n",
    "len(indiv_combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above we can see that the individual combinations of dimensions are not equally frequent. Depending on how we attempt to solve our classification problem later on, this is something we want to keep in mind.\n",
    "\n",
    "As another exploration step, let's take a look at the number of characters in the `text`-column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD3CAYAAAANMK+RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEmxJREFUeJzt3X2QXXV9x/F3kuWhsQuuesVxxMm06rcd24pBDUWFDKgUKU0H25FxwFFGxTZYonSAIjTo0KkgYAEfsGAGZGS0EihiJyWtIIMUmjENo1b6RVBLO0Vd4gZWomDC9o97Vq/J3t2zd+/eh1/er7/uOfe3537u7snnnJx77jlLpqamkCQNv6X9DiBJ6g4LXZIKYaFLUiEsdEkqhIUuSYUY6eeLj49P1j7FZmxsORMTOxczzqIyf3+Zv7/M312NxuiSmeYPzR76yMiyfkdYEPP3l/n7y/y9MTSFLkmanYUuSYWw0CWpEBa6JBXCQpekQljoklQIC12SCmGhS1IhLHRJKkRfv/qv7jntI3e0fW7Ducf0MImkfnEPXZIKYaFLUiEsdEkqhMfQ9wHtjq97bF0qy5yFHhH7ARuAFcABwEXAt4HrgCngW8DazHwmItYDJwC7gHWZuWVxYkuS9lRnD/0UYHtmnhoRzwW2AfcD52fmVyPiamBNRPw3cDSwCjgU2Ai8epFy77NmO5tF0r6tTqF/EbipZXoXcDhwVzW9CXgTkMDmzJwCHomIkYhoZOZ4NwPvKyxuSfM1Z6Fn5k8AImKUZrGfD1xaFTfAJHAwcBCwveVHp+e3LfSxseXzuhNIozFae+wgGrT8880zaPnny/z9Zf7FV+tD0Yg4FLgF+GRm3hgRl7Q8PQrsAJ6oHu85v6353KOv0RhlfHyy9vhBM4j555NnEPPPh/n7y/zd1W7jUudD0UOAzcAZmfmVava2iFidmV8FjgfuBB4CLomIS4EXAUsz87EuZC+ah1YkdUudPfTzgDHggoi4oJp3JnBlROwPPADclJm7I+Ju4F6a57evXYzAkqSZ1TmGfibNAt/T0TOMvRC4cMGpJEnz5jdFJakQFrokFcJCl6RCWOiSVAgLXZIKYaFLUiEsdEkqhIUuSYWw0CWpEBa6JBXCQpekQljoklQIC12SCmGhS1IhLHRJKoSFLkmFsNAlqRB1bxK9Crg4M1dHxOeBF1RPrQDuy8yTI+JLwHOBnwM/zczjFyOwJGlmdW4SfTZwKvAkQGaeXM0fo3lz6PdXQ18CvDwzpxYnqiRpNnUOuTwMnDTD/A8BV2XmoxFxCPBs4LaI+FpE/GE3Q0qS5lbnJtEbI2JF67yIeD5wLL/cO98fuAy4AngOcE9EbMnMH8227LGx5YyMLKsdttEYrT12EA1a/vnmGbT882X+/jL/4qt1DH0GfwLcmJm7q+kfAFdn5i7gRxGxDQhg1kKfmNhZ+wUbjVHGxyc7jNt/g5j/xLNunXH+hnOP2WveIOafD/P3l/m7q93GpdOzXN4AbNpj+h8AIuLXgd8BHuhw2ZKkDnRa6AF8d3oiMzcB34mI+4DNwHmZ+VgX8kmSaqp1yCUzvw8c0TL98hnGrOteLEnSfPnFIkkqhIUuSYWw0CWpEBa6JBXCQpekQljoklQIC12SCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVwkKXpEJY6JJUCAtdkgphoUtSISx0SSpErTsWRcQq4OLMXB0RK4HbgO9UT38qM78QEeuBE4BdwLrM3LIoiSVJM5qz0CPibOBU4Mlq1krg8sy8rGXMSuBoYBVwKLAReHXX00qS2qqzh/4wcBJwQzV9OBARsYbmXvo64HXA5sycAh6JiJGIaGTm+GwLHhtbzsjIstphG43R2mMHzYln3drvCLW1+z0P8+8fzN9v5l98cxZ6Zm6MiBUts7YA12bm1oj4ILAe2AFsbxkzCRwMzFroExM7awdtNEYZH5+sPV6dm+n3POy/f/P3l/m7q93GpZMPRW/JzK3Tj4FXAk8Ara8wSrPkJUk90kmh3x4Rr6keHwtsBe4BjouIpRHxYmBpZj7WrZCSpLnVOstlD38GfDwingZ+ALwnM5+IiLuBe2luJNZ2MaMkqYYlU1NTfXvx8fHJ2i8+aMew5uu0j9zR7wgLtuHcY/odoWPDvv6Yv78GLX+jMbpkpvl+sUiSCmGhS1IhLHRJKkQnH4qqjRKOk89mtvc3zMfXpVK4hy5JhbDQJakQFrokFcJCl6RCWOiSVAgLXZIKYaFLUiEsdEkqhIUuSYWw0CWpEBa6JBXCQpekQljoklSIWldbjIhVwMWZuToiDgOuAnYDTwFvz8wfRsSVwGuB6dt6rMnMxxcjtAZPuysxehVGqXfmLPSIOBs4FXiymnUF8L7MvD8iTgfOAT4ArASO8+bQktQfdfbQHwZOAm6opk/OzEdbfv5nEbEUeCnw9xFxCPCZzNww14LHxpYzMrKsdthGY7T2WA2GQfqbDVKWTpi/v4Yh/5yFnpkbI2JFy/SjABFxJHAGcBTwLJqHYS4HlgF3RsTXM/Mbsy17YmJn7aCDdpNW1TMof7NhX3/M31+Dlr/dxqWjD0Uj4q3A1cAJmTkO7ASuyMydmTkJ3AG8osOskqQOzPsWdBFxCnA6sDozf1zNfhnw+YhYSXMj8Trg+q6llCTNaV6FHhHLgCuBR4CbIwLgrsxcHxGfA+4Dfg58NjP/s9thJUnt1Sr0zPw+cEQ1+Zw2Yy4BLulOLEnSfPnFIkkqhIUuSYWw0CWpEBa6JBXCQpekQljoklQIC12SCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVwkKXpEJY6JJUCAtdkgphoUtSISx0SSpErTsWRcQq4OLMXB0RLwGuA6aAbwFrM/OZiFgPnADsAtZl5pZFyixJmsGce+gRcTZwLXBgNety4PzMfD2wBFhT3Rz6aGAVcDLwicWJK0lqp84e+sPAScAN1fThwF3V403Am4AENmfmFPBIRIxERCMzx2db8NjYckZGltUO22iM1h6rwTBIf7NBytIJ8/fXMOSfs9Azc2NErGiZtaQqboBJ4GDgIGB7y5jp+bMW+sTEztpBG41Rxscna4/XYBiUv9mwrz/m769By99u49LJh6LPtDweBXYAT1SP95wvSeqRTgp9W0Ssrh4fD9wN3AMcFxFLI+LFwNLMfKxLGSVJNdQ6y2UPZwHXRMT+wAPATZm5OyLuBu6luZFY28WMkqQaahV6Zn4fOKJ6/CDNM1r2HHMhcGH3okmS5sMvFklSISx0SSqEhS5JhbDQJakQFrokFaKT0xb3ead95I5+R5CkvbiHLkmFsNAlqRAWuiQVwkKXpEJY6JJUCAtdkgphoUtSISx0SSqEhS5JhbDQJakQHX31PyLeAbyjmjwQOAx4G/BR4H+q+esz864F5pMk1dRRoWfmdcB1ABHxCWADsBI4OzM3diucJKm+BV2cKyJeBbw8M9dGxCbglRGxDtgCnJOZu7oRUsOr3YXMNpx7TI+TSOVb6NUWzwM+VD3+F+Afge8BVwPvBT4+2w+PjS1nZGRZ7RdrNEY7S6mB04+/5bCvP+bvr2HI33GhR8Szgd/KzDurWRsyc0f13K3AW+ZaxsTEztqv12iMMj4+2UlUDaBe/y2Hff0xf38NWv52G5eFnOVyFPCvABGxBPhGRLyoeu5YYOsCli1JmqeFHHIJ4LsAmTkVEe8Cbo6InwLfBq7pQj4VymPrUvd1XOiZ+dE9pjcDmxecSJLUEb9YJEmF8J6is/DeoZKGiXvoklQIC12SCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVwkKXpEL4xSINFK/xInXOPXRJKoSFLkmFsNAlqRAWuiQVwkKXpEJY6JJUiIXcJHob8Hg1+T3g08AVwC5gc2Z+aOHxJEl1dVToEXEgQGaubpl3P/AWmvcZ/aeIWJmZ/9GNkJKkuXW6h/4KYHlEbK6WcSFwQGY+DBARtwPHAha6JPVIp4W+E7gUuBZ4KbAJ2NHy/CTwG3MtZGxsOSMjy2q/aKMxOr+UKkY3/vbDvv6Yv7+GIX+nhf4g8FBmTgEPRsTjwHNanh/lVwt+RhMTO2u/YKMxyvj45HxzqhAL/dsP+/pj/v4atPztNi6dFvppwO8Cfx4RLwSWA09GxG/SPIZ+HOCHouqa2W7Y7XVepKZOC/0zwHUR8TVgimbBPwN8DlhG8yyXf+9ORElSHR0VemY+DbxthqeOWFgcSVKn/GKRJBXCQpekQljoklQIC12SCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVwkKXpEJY6JJUiI5vQVeS2a7kJ0nDwj10SSqEhS5JhbDQJakQFrokFcJCl6RCdHSWS0TsB2wAVgAHABcB/wvcBnynGvapzPxCFzJKkmro9LTFU4DtmXlqRDwX2AZ8GLg8My/rWjpJUm2dFvoXgZtapncBhwMREWto7qWvy8zJBeaTJNW0ZGpqquMfjohR4EvANTQPvXwjM7dGxAeBscz8y9l+fteu3VMjI8s6fv1uOfGsW/sdQQtw22Vr+h1B6rUlM83s+JuiEXEocAvwycy8MSKenZk7qqdvAa6aaxkTEztrv16jMcr4uDv82lud9WLY1x/z99eg5W80Rmec3+mHoocAm4EzMvMr1ezbI+J9mbkFOBbY2smypcXW7lIPG849psdJpO7qdA/9PGAMuCAiLqjmfQD4u4h4GvgB8J4u5JPm5LV4pKaOCj0zzwTOnOGpIxcWR5LUKb9YJEmFsNAlqRAWuiQVYp+6wYUfnkkqmXvoklQIC12SCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVYp86D12aTSffU/AKjRok7qFLUiEsdEkqhIdcpAXwZhkaJO6hS1IhLHRJKkRXD7lExFLgk8ArgKeAd2XmQ918jWn+V1eDzPVT/dDtY+h/DByYmb8fEUcAlwFruvwa0tDqZtHP9zTLbm5M3GANpm4X+uuAfwbIzPsi4lVdXv6cvOa5htFs620/S7Jb/55OPOvWGed3c0M2iBuTXv9dl0xNTXVtYRFxLbAxMzdV048Av5GZu7r2IpKkGXX7Q9EngNHW5VvmktQb3S70e4A3A1TH0L/Z5eVLktro9jH0W4A3RsS/AUuAd3Z5+ZKkNrp6DF2S1D9+sUiSCmGhS1IhLHRJKsTAX22xl5cT6ERE7AdsAFYABwAXAd8GrgOmgG8BazPzmYhYD5wA7ALWZeaWiHjJTGN7/B6eD2wF3lhlG5rsVf6/Av4I2J/munLXMLyHat25nua6sxt4N0Py+4+IVcDFmbm6XY75ZJ5pbA/zHwZcRfNv8BTw9sz8YUS8Gzi9ynRRZn45Ip4H3Aj8GvB/wDszc+dMYxczfzvDsIf+i8sJAOfSvJzAIDkF2J6ZrweOBz4OXA6cX81bAqyJiJXA0cAq4GTgE9XP7zW2l+GrUvk08NN2eQY1O0BErAaOBF5bZTx0plwD+h7eDIxk5pHAh4G/GYbsEXE2cC1wYLsc88k8y9he5b8CeF9mrgZuBs6JiBcAf0FzvToO+NuIOAD4a+DGKv824PRZxvbcMBT6r1xOAOj55QTm8EXggpbpXcDhNPcSATYBb6D5PjZn5lRmPgKMRESjzdheuhS4mubeBm3yDGp2aP4D+ibNU2ZvA77cJtcgvocHqxxLgYOAnw9J9oeBk1qmF5q53dhe5T85M++vHo8APwNeA9yTmU9l5uPAQ8Dv0dJHLfnbje25YSj0g4DHW6Z3R8TAHCrKzJ9k5mREjAI3AecDSzJz+nzQSeBg9n4f0/NnGtsTEfEOYDwzb2+ZPRTZWzyP5kb+T4H3Ap+j+Q3lYXgPP6F5uOW/gGuAK9vkGajsmbmR5sZn2kIztxu7KPbMn5mPAkTEkcAZwMdmydQ6vy/5ZzMMhT7wlxOIiEOBO4EbMvNGoPU45iiwg73fx/T8mcb2ymk0vwj2VeAw4LPA82fIM4jZp20Hbs/MpzMzae5dtf5jGuT38H6a2V9G8zOi62l+DrBnnkHM3mqh63u7sT0TEW+l+T/VEzJzfJZMrfMHJv+0YSj0gb6cQEQcAmwGzsnMDdXsbdWxXWgeV7+b5vs4LiKWRsSLaW6YHmszticy86jMPLo6dng/8HZg0zBkb/E14A8iYklEvBB4FvCVIXkPE/xyz+7HwH5t8gxi9lYLzdxubE9ExCk098xXZ+Z3q9lbgNdHxIERcTDw2zQ/xP1FH7Xkbze25wbm0MUsBv1yAucBY8AFETF9LP1M4MqI2B94ALgpM3dHxN3AvTQ3pGursWcB17SO7Wn6ve2VZ5CzV2ceHEXzH9V0tu8NyXv4GLChyrU/zXXp60OSvdWC1plZxi66iFhG81DXI8DNEQFwV2auj4graRb2UuCDmfmziLgIuL46q+Ux4G2Z+eRMY3v1Hlr51X9JKsQwHHKRJNVgoUtSISx0SSqEhS5JhbDQJakQFrokFcJCl6RC/D//RsGP6VKWpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "char_counts = essays_raw.text.str.len()\n",
    "\n",
    "print(char_counts.hist(bins = int(np.sqrt(len(essays_raw)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most essays appear to be between 2000 and 4000 characters long. There appear to some outliers as well (e.g. at least one essay with more than 12000 characters). This is something we want to keep in mind for later, as well.\n",
    "\n",
    "Also, we should look at some sample essays to see which kind of preprocessing we should to later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well, right now I just woke up from a mid-day nap. It\\'s sort of weird, but ever since I moved to Texas, I have had problems concentrating on things. I remember starting my homework in  10th grade as soon as the clock struck 4 and not stopping until it was done. Of course it was easier, but I still did it. But when I moved here, the homework got a little more challenging and there was a lot more busy work, and so I decided not to spend hours doing it, and just getting by. But the thing was that I always paid attention in class and just plain out knew the stuff, and now that I look back, if I had really worked hard and stayed on track the last two years without getting  lazy, I would have been a genius, but hey, that\\'s all good. It\\'s too late to correct the past, but I don\\'t really know how to stay focused n the future. The one thing I know is that when  people say that b/c they live on campus they can\\'t concentrate, it\\'s b. s. For me it would be easier there, but alas, I\\'m living at home under the watchful eye of my parents and a little nagging sister that just nags and nags and nags. You get my point. Another thing is, is that it\\'s just a hassle to have to go all the way back to  school to just to go to library to study. I need to move out, but I don\\'t know how to tell them. Don\\'t get me wrong, I see where they\\'re coming from and why they don\\'t  want me to move out, but I need to get away and be on my own. They\\'ve sheltered me so much and I don\\'t have a worry in the world. The only thing that they ask me to do is keep my room clean and help out with the business once in a while, but I can\\'t even do that. But I need to. But I got enough money from UT to live at a dorm or apartment  next semester and I think I’ll take advantage of that. But off that topic now, I went to sixth street last night and had a blast. I haven\\'t been there in so long. Now I know why I love Austin so much. When I lived in VA, I used to go up to DC all the time and had a blast, but here, there are so many students running around at night. I just want to have some fun and I know that I am responsible enough to be able to  have fun, but keep my priorities straight. Living at home, I can\\'t go out at all without them asking where? with who?  why?  when are you coming back?  and all those  questions. I just wish I could be treated like a responsible person for once, but  my sister screwed that up for me. She went crazy the second she moved into college and messed up her whole college career by partying too much. And that\\'s the ultimate reason that they don\\'t want me to go and have fun. But I\\'m not little anymore,  and they need to let me go and explore the world, but I’m Indian; with Indian culture, with Indian values. They go against \"having fun. \"  I mean in the sense of meeting people or going out with people or partying or just plain having fun. My school is difficult already, but somehow I think that having more freedom will put more pressure on me to  do better in school b/c that\\'s what my parents and ultimately I expect of myself. Well it\\'s been fun writing, I don\\'t know if you go anything out of this writing, but it helped me get some of my thoughts into order. So I hope you had fun reading it and good luck TA\\'s.    '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_raw.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text looks pretty messy: For example, there are a lot of special characters and abbreviations. This is not optimal if you want to feed the text to a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing\n",
    "\n",
    "In this part, we will create a nice and clean dataset that we can feed into a machine learning model.\n",
    "First, we drop the `authid` column because we actually do not need it for the classification task. Note that we define a function for each preprocessing step, so that we have the option to build a pipeline that combines all steps later on. We implement these functions as *fit transformer objects* to be able to feed them into pipelines later on.\n",
    "\n",
    "## 3.1 Define preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ext</th>\n",
       "      <th>neu</th>\n",
       "      <th>agr</th>\n",
       "      <th>con</th>\n",
       "      <th>opn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text ext neu agr con opn\n",
       "0  Well, right now I just woke up from a mid-day ...   n   y   y   n   y\n",
       "1  Well, here we go with the stream of consciousn...   n   n   y   n   n\n",
       "2  An open keyboard and buttons to push. The thin...   n   y   n   y   y\n",
       "3  I can't believe it!  It's really happening!  M...   y   n   y   y   n\n",
       "4  Well, here I go with the good old stream of co...   y   n   y   n   y"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.drop([\"authid\"], axis = 1)\n",
    "        return df\n",
    "    \n",
    "dropper = ColDropper()\n",
    "dropper.transform(essays_raw.copy()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also implement a class that converts the `y` labels to 1s on the `n` labels to 0s for each personality dimension. This is neccessary because most algorithms can only handle numeric labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authid</th>\n",
       "      <th>text</th>\n",
       "      <th>ext</th>\n",
       "      <th>neu</th>\n",
       "      <th>agr</th>\n",
       "      <th>con</th>\n",
       "      <th>opn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authid                                               text  ext  \\\n",
       "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...    0   \n",
       "1  1997_605191.txt  Well, here we go with the stream of consciousn...    0   \n",
       "2  1997_687252.txt  An open keyboard and buttons to push. The thin...    0   \n",
       "3  1997_568848.txt  I can't believe it!  It's really happening!  M...    1   \n",
       "4  1997_688160.txt  Well, here I go with the good old stream of co...    1   \n",
       "\n",
       "   neu  agr  con  opn  \n",
       "0    1    1    0    1  \n",
       "1    0    1    0    0  \n",
       "2    1    0    1    1  \n",
       "3    0    1    1    0  \n",
       "4    0    1    0    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LabelTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df['ext'], df['neu'], df['agr'], df['con'], df['opn'] = [[1 if x == 'y' else 0 for x in col] \\\n",
    "                                                                                     for col in [df['ext'],\n",
    "                                                                                                 df['neu'],\n",
    "                                                                                                 df['agr'],\n",
    "                                                                                                 df['con'], \n",
    "                                                                                                 df['opn']]]\n",
    "        return df\n",
    "    \n",
    "lbl_trnsfr = LabelTransformer()\n",
    "lbl_trnsfr.transform(essays_raw.copy()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output above, the string labels got turned into 0s and 1s.\n",
    "\n",
    "Next, we create a function to clean the `text` column. This function turns all letters to lower case and removes some abbreviations that are common in the english language. It also removes special characters and multiple consecutive spaces. We also test this function on a sample enssay to ensure that it works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'well right now i just woke up from a mid day nap it sort of weird but ever since i moved to texas i have had problems concentrating on things i remember starting my homework in 10th grade as soon as the clock struck 4 and not stopping until it was done of course it was easier but i still did it but when i moved here the homework got a little more challenging and there was a lot more busy work and so i decided not to spend hours doing it and just getting by but the thing was that i always paid attention in class and just plain out knew the stuff and now that i look back if i had really worked hard and stayed on track the last two years without getting lazy i would have been a genius but hey that all good it too late to correct the past but i do not really know how to stay focused n the future the one thing i know is that when people say that because they live on campus they can not concentrate it b s for me it would be easier there but alas i am living at home under the watchful eye of my parents and a little nagging sister that just nags and nags and nags you get my point another thing is is that it just a hassle to have to go all the way back to school to just to go to library to study i need to move out but i do not know how to tell them do not get me wrong i see where they are coming from and why they do not want me to move out but i need to get away and be on my own they have sheltered me so much and i do not have a worry in the world the only thing that they ask me to do is keep my room clean and help out with the business once in a while but i can not even do that but i need to but i got enough money from ut to live at a dorm or apartment next semester and i think i will take advantage of that but off that topic now i went to sixth street last night and had a blast i have not been there in so long now i know why i love austin so much when i lived in va i used to go up to dc all the time and had a blast but here there are so many students running around at night i just want to have some fun and i know that i am responsible enough to be able to have fun but keep my priorities straight living at home i can not go out at all without them asking where with who why when are you coming back and all those questions i just wish i could be treated like a responsible person for once but my sister screwed that up for me she went crazy the second she moved into college and messed up her whole college career by partying too much and that the ultimate reason that they do not want me to go and have fun but i am not little anymore and they need to let me go and explore the world but i am indian with indian culture with indian values they go against having fun i mean in the sense of meeting people or going out with people or partying or just plain having fun my school is difficult already but somehow i think that having more freedom will put more pressure on me to do better in school because that what my parents and ultimately i expect of myself well it been fun writing i do not know if you go anything out of this writing but it helped me get some of my thoughts into order so i hope you had fun reading it and good luck ta'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"i’m\", \"i am \", text)\n",
    "    text = re.sub('b/c', 'because', text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"’ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "clean_text(essays_raw.text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we take a look at our sample essay now, it looks pretty good. Note that to make things simpler a string like `it's` is striped down to just `it`. We chose to do so because `is` is a typical stopword that we'll remove anyway.\n",
    "\n",
    "Now, we implement a class `TextCleaner` that applies the `clean_text` function to every row in the `text` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    well right now i just woke up from a mid day n...\n",
       "1    well here we go with the stream of consciousne...\n",
       "2    an open keyboard and buttons to push the thing...\n",
       "3    i can not believe it it really happening my pu...\n",
       "4    well here i go with the good old stream of con...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, pd_series):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, pd_series):\n",
    "        pd_series = pd_series.apply(clean_text)\n",
    "        return pd_series\n",
    "\n",
    "cleaner = TextCleaner()\n",
    "cleaner.transform(essays_raw['text'].copy()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks alright. Our preprocessing functions to work fine. So it's time to build pipelines that combine the different preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Create a training set and a testing set\n",
    "\n",
    "We create a train test split from the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1973,)\n",
      "(494,)\n",
      "(1973, 6)\n",
      "(494, 6)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(essays_raw, random_state = 1, test_size = 0.2, shuffle = True)\n",
    "\n",
    "X_train = train['text'].copy()\n",
    "y_train = train.copy().drop('text', axis = 1)\n",
    "\n",
    "X_test = test['text'].copy()\n",
    "y_test = test.copy().drop('text', axis = 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Build and apply preprocessing pipelines\n",
    "\n",
    "We create two pipelines (one for the predictor, one for the labels) that integrate the different preprocessing functions. Note that use the class `TfidfVectorizer`from `sklearn` to tokenize the text data and compute tf-idf statistics. This class can also be used to remove stop words from text input. Stop words are words that occur very frequently and thus do not contain much information about the specific content of a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prep_pipeline = Pipeline([('txtclean', TextCleaner()),\n",
    "                            ('tfidf', TfidfVectorizer(stop_words = stop_words))])\n",
    "\n",
    "y_prep_pipeline = Pipeline([('idcoldrop', ColDropper()),\n",
    "                            ('lbltransf', LabelTransformer())])\n",
    "\n",
    "X_train_prepared = X_prep_pipeline.fit_transform(X_train)\n",
    "y_train_prepared = y_prep_pipeline.fit_transform(y_train)\n",
    "\n",
    "X_test_prepared = X_prep_pipeline.fit_transform(X_test)\n",
    "y_test_prepared = y_prep_pipeline.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Explore models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for ext using MultinomialNB: 0.747592498732894\n",
      "Accuracy for neu using MultinomialNB: 0.9574252407501267\n",
      "Accuracy for agr using MultinomialNB: 0.6031424227065383\n",
      "Accuracy for con using MultinomialNB: 0.8722757222503801\n",
      "Accuracy for opn using MultinomialNB: 0.9077546882919412\n",
      "\n",
      "\n",
      "Accuracy for ext using a RandomForestClassifier: 1.0\n",
      "Accuracy for neu using a RandomForestClassifier: 1.0\n",
      "Accuracy for agr using a RandomForestClassifier: 1.0\n",
      "Accuracy for con using a RandomForestClassifier: 1.0\n",
      "Accuracy for opn using a RandomForestClassifier: 1.0\n",
      "\n",
      "\n",
      "Accuracy for ext using LogisticRegression: 0.9229599594526102\n",
      "Accuracy for neu using LogisticRegression: 0.9183983781044095\n",
      "Accuracy for agr using LogisticRegression: 0.9102889001520527\n",
      "Accuracy for con using LogisticRegression: 0.9270146984287887\n",
      "Accuracy for opn using LogisticRegression: 0.8667004561581348\n"
     ]
    }
   ],
   "source": [
    "# Naive bayes classifier\n",
    "nb_clf = MultinomialNB(fit_prior = True, class_prior = None)\n",
    "for category in ['ext', 'neu', 'agr', 'con', 'opn']:\n",
    "    nb_clf.fit(X_train_prepared, y_train_prepared[category])\n",
    "    preds = nb_clf.predict(X_train_prepared)\n",
    "    print('Accuracy for {} using MultinomialNB: {}'.format(category, accuracy_score(y_train_prepared[category], preds)))\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "    # Random forrests\n",
    "rb_clf = RandomForestClassifier(n_estimators = 200)\n",
    "for category in ['ext', 'neu', 'agr', 'con', 'opn']:\n",
    "    rb_clf.fit(X_train_prepared, y_train_prepared[category])\n",
    "    preds = rb_clf.predict(X_train_prepared)\n",
    "    print('Accuracy for {} using a RandomForestClassifier: {}'.format(category, accuracy_score(y_train_prepared[category], preds)))\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "log_clf = LogisticRegression(solver='sag')\n",
    "for category in ['ext', 'neu', 'agr', 'con', 'opn']:\n",
    "    log_clf.fit(X_train_prepared, y_train_prepared[category])\n",
    "    preds = log_clf.predict(X_train_prepared)\n",
    "    print('Accuracy for {} using LogisticRegression: {}'.format(category, accuracy_score(y_train_prepared[category], preds)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForrestClassifer appears to do very well with perfect accuracy for all dimensions, so we further explore this type of model.\n",
    "\n",
    "Next steps:\n",
    "* Compute other metrics: F1-score, precision, recall\n",
    "* Hyperparameter tuning\n",
    "* Final step: Compute performance metric on test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
