{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup\n",
    "We start off by importing the Python libraries we need. We also import the `essays` dataset (`essays.csv`) that we can find in the `data` directory of our project. We also format the column names, so that they are easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT cEXT  \\\n",
       "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...    n   \n",
       "1  1997_605191.txt  Well, here we go with the stream of consciousn...    n   \n",
       "2  1997_687252.txt  An open keyboard and buttons to push. The thin...    n   \n",
       "3  1997_568848.txt  I can't believe it!  It's really happening!  M...    y   \n",
       "4  1997_688160.txt  Well, here I go with the good old stream of co...    y   \n",
       "\n",
       "  cNEU cAGR cCON cOPN  \n",
       "0    y    y    n    y  \n",
       "1    n    y    n    n  \n",
       "2    y    n    y    y  \n",
       "3    n    y    y    n  \n",
       "4    n    y    n    y  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import re\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "# import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "essays_raw = pd.read_csv('data/essays.csv', engine='python');\n",
    "\n",
    "def clean_colnames(df):\n",
    "    df.columns = df.columns.str.replace(\"c|#\", \"\").str.lower()\n",
    "    return df\n",
    "    \n",
    "essays = clean_colnames(essays_raw.copy())\n",
    "essays_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inpect the data\n",
    "\n",
    "Let's take a quick look at the structure of the `essays` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            authid                                               text ext neu  \\\n",
      "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...   n   y   \n",
      "1  1997_605191.txt  Well, here we go with the stream of consciousn...   n   n   \n",
      "2  1997_687252.txt  An open keyboard and buttons to push. The thin...   n   y   \n",
      "3  1997_568848.txt  I can't believe it!  It's really happening!  M...   y   n   \n",
      "4  1997_688160.txt  Well, here I go with the good old stream of co...   y   n   \n",
      "\n",
      "  agr con opn  \n",
      "0   y   n   y  \n",
      "1   y   n   n  \n",
      "2   n   y   y  \n",
      "3   y   y   n  \n",
      "4   y   n   y  \n",
      "\n",
      "Number of rows and columns: (2467, 7) \n",
      "\n",
      "All author ids are unique!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "authid    0\n",
       "text      0\n",
       "ext       0\n",
       "neu       0\n",
       "agr       0\n",
       "con       0\n",
       "opn       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first few rows of the dataset\n",
    "print(essays.head())\n",
    "\n",
    "# Print the number of rows and colums\n",
    "print(\"\\nNumber of rows and columns: {} \\n\".format(essays.shape))\n",
    "\n",
    "# Check if author ids are unique\n",
    "if len(essays['authid']) == len(essays):\n",
    "    print('All author ids are unique!')\n",
    "else:\n",
    "    print('Author ids are not unique!')\n",
    "    \n",
    "# Check if there are missing values in the dataset:\n",
    "essays.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a datasset containing 2467 essays from the same number of individual authors. We can also see that the dataset does not contain any missing values. Each essay is associated with an author id and 5 binary labels (one label per personality dimension):\n",
    "\n",
    "* Extraversion (`ext`)\n",
    "* Neuroticism (`neu`)\n",
    "* Agreeableness (`agr`)\n",
    "* Conscientiousness (`con`)\n",
    "* Openess (`opn`)\n",
    "\n",
    "Note that in psychological theory, the Big Five model actually considers all five traits as independent continious dimensions (and even defines sub dimensions - so-called facets - for each of them). However, for this machine learning task, the labels in our datasets represent just binary categories (e.g. a value of `y` in the `neu`-column indicates that the author of the given essay is neurotic).\n",
    "\n",
    "Obviously, our goal is to predict the five binary labels for a given essay. In the other words, the task at hand is a binary multi label classification task. Before we create a train-test split and preprocess our data, let's explore it a little bit further. For example we can look at the distribution of labels for each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>dimension</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "      <td>ext</td>\n",
       "      <td>1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y</td>\n",
       "      <td>ext</td>\n",
       "      <td>1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n</td>\n",
       "      <td>neu</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y</td>\n",
       "      <td>neu</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>agr</td>\n",
       "      <td>1157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>y</td>\n",
       "      <td>agr</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n</td>\n",
       "      <td>con</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>y</td>\n",
       "      <td>con</td>\n",
       "      <td>1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n</td>\n",
       "      <td>opn</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>y</td>\n",
       "      <td>opn</td>\n",
       "      <td>1271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label dimension  count\n",
       "0     n       ext   1191\n",
       "1     y       ext   1276\n",
       "2     n       neu   1234\n",
       "3     y       neu   1233\n",
       "4     n       agr   1157\n",
       "5     y       agr   1310\n",
       "6     n       con   1214\n",
       "7     y       con   1253\n",
       "8     n       opn   1196\n",
       "9     y       opn   1271"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = pd.melt(essays.iloc[:, 2:7].apply(pd.Series.value_counts).reset_index().copy(),\n",
    "                       id_vars = ['index'], var_name = 'dimension', value_name = 'count').rename(columns = {'index': 'label'})\n",
    "\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15bbb6fcd68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = \"dimension\", y = \"count\", hue = \"label\", data = label_counts)\n",
    "plt.legend(loc = 'center right')\n",
    "plt.legend(bbox_to_anchor = (1.05, 1), loc = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot we can see that for each dimension the number of samples on the positive class (`y`) is roughly equal to the number of samples of the negative class (`n`). In other words, our dataset is appears to be pretty balanced (at least, if you look at each dimension separatly) Let's also look at the counts of individual combinations of dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indiv_combs = (essays['ext'] + essays['neu'] + essays['agr'] + essays['con'] + essays['opn']). \\\n",
    "               value_counts()\n",
    "\n",
    "indiv_combs.plot(kind = \"bar\", color = \"lightblue\")\n",
    "len(indiv_combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above we can see that the individual combinations of dimensions are not equally frequent. Depending on how we attempt to solve our classification problem later on, this is something we want to keep in mind.\n",
    "\n",
    "As another exploration step, let's take a look at the number of characters in the `text`-column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "char_counts = essays.text.str.len()\n",
    "\n",
    "print(char_counts.hist(bins = int(np.sqrt(len(essays)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most essays appear to be between 2000 and 4000 characters long. There appear to some outliers as well (e.g. at least one essay with more than 12000 characters). This is something we want to keep in mind for later, as well.\n",
    "\n",
    "Also, we should look at some sample essays to see which kind of preprocessing we should to later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well, right now I just woke up from a mid-day nap. It\\'s sort of weird, but ever since I moved to Texas, I have had problems concentrating on things. I remember starting my homework in  10th grade as soon as the clock struck 4 and not stopping until it was done. Of course it was easier, but I still did it. But when I moved here, the homework got a little more challenging and there was a lot more busy work, and so I decided not to spend hours doing it, and just getting by. But the thing was that I always paid attention in class and just plain out knew the stuff, and now that I look back, if I had really worked hard and stayed on track the last two years without getting  lazy, I would have been a genius, but hey, that\\'s all good. It\\'s too late to correct the past, but I don\\'t really know how to stay focused n the future. The one thing I know is that when  people say that b/c they live on campus they can\\'t concentrate, it\\'s b. s. For me it would be easier there, but alas, I\\'m living at home under the watchful eye of my parents and a little nagging sister that just nags and nags and nags. You get my point. Another thing is, is that it\\'s just a hassle to have to go all the way back to  school to just to go to library to study. I need to move out, but I don\\'t know how to tell them. Don\\'t get me wrong, I see where they\\'re coming from and why they don\\'t  want me to move out, but I need to get away and be on my own. They\\'ve sheltered me so much and I don\\'t have a worry in the world. The only thing that they ask me to do is keep my room clean and help out with the business once in a while, but I can\\'t even do that. But I need to. But I got enough money from UT to live at a dorm or apartment  next semester and I think I’ll take advantage of that. But off that topic now, I went to sixth street last night and had a blast. I haven\\'t been there in so long. Now I know why I love Austin so much. When I lived in VA, I used to go up to DC all the time and had a blast, but here, there are so many students running around at night. I just want to have some fun and I know that I am responsible enough to be able to  have fun, but keep my priorities straight. Living at home, I can\\'t go out at all without them asking where? with who?  why?  when are you coming back?  and all those  questions. I just wish I could be treated like a responsible person for once, but  my sister screwed that up for me. She went crazy the second she moved into college and messed up her whole college career by partying too much. And that\\'s the ultimate reason that they don\\'t want me to go and have fun. But I\\'m not little anymore,  and they need to let me go and explore the world, but I’m Indian; with Indian culture, with Indian values. They go against \"having fun. \"  I mean in the sense of meeting people or going out with people or partying or just plain having fun. My school is difficult already, but somehow I think that having more freedom will put more pressure on me to  do better in school b/c that\\'s what my parents and ultimately I expect of myself. Well it\\'s been fun writing, I don\\'t know if you go anything out of this writing, but it helped me get some of my thoughts into order. So I hope you had fun reading it and good luck TA\\'s.    '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text looks pretty messy: For example, there are a lot of special characters and abbreviations. This is not optimal if you want to feed the text to a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing\n",
    "\n",
    "In this part, we will create classes that allow us clean our dataset. The goal is to have a nice and clean dataset that we can feed into a machine learning model.\n",
    "\n",
    "Note that we define a class for each preprocessing step, so that we can build a pipeline that combines all steps later on. We implement these classes as *transformer classes* to be able to feed them into pipelines. While `sklearn`comes with a lot of useful *transformer classes* already, we implement most classes we need by hand to get some practice.\n",
    "\n",
    "We also test each class on a copy of the dataset to make sure that the classes work as expected.\n",
    "\n",
    "## 3.1 Define preprocessing functions\n",
    "First, a class that cleans the column names of the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authid</th>\n",
       "      <th>text</th>\n",
       "      <th>ext</th>\n",
       "      <th>neu</th>\n",
       "      <th>agr</th>\n",
       "      <th>con</th>\n",
       "      <th>opn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authid                                               text ext neu  \\\n",
       "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...   n   y   \n",
       "1  1997_605191.txt  Well, here we go with the stream of consciousn...   n   n   \n",
       "2  1997_687252.txt  An open keyboard and buttons to push. The thin...   n   y   \n",
       "3  1997_568848.txt  I can't believe it!  It's really happening!  M...   y   n   \n",
       "4  1997_688160.txt  Well, here I go with the good old stream of co...   y   n   \n",
       "\n",
       "  agr con opn  \n",
       "0   y   n   y  \n",
       "1   y   n   n  \n",
       "2   n   y   y  \n",
       "3   y   y   n  \n",
       "4   y   n   y  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ColNameCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X.columns = X.columns.str.replace(\"c|#\", \"\").str.lower()\n",
    "        return X\n",
    "\n",
    "cleaner = ColNameCleaner()\n",
    "cleaner.transform(essays_raw.copy()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implement a class that drops the `#AUTHID` / `authid` column because we actually do not need it for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT cEXT cNEU cAGR cCON cOPN\n",
       "0  Well, right now I just woke up from a mid-day ...    n    y    y    n    y\n",
       "1  Well, here we go with the stream of consciousn...    n    n    y    n    n\n",
       "2  An open keyboard and buttons to push. The thin...    n    y    n    y    y\n",
       "3  I can't believe it!  It's really happening!  M...    y    n    y    y    n\n",
       "4  Well, here I go with the good old stream of co...    y    n    y    n    y"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.drop(columns = self.column)\n",
    "        return X\n",
    "    \n",
    "dropper = ColDropper(column = \"#AUTHID\")\n",
    "dropper.transform(essays_raw.copy()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also implement a class that converts the `y` labels to 1s on the `n` labels to 0s for each personality dimension. We do this because some algorithms can not string labels. Also using a boolean data type is more computionally efficient. Note that in order to use this class the column names need to be cleaned up already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authid</th>\n",
       "      <th>text</th>\n",
       "      <th>ext</th>\n",
       "      <th>neu</th>\n",
       "      <th>agr</th>\n",
       "      <th>con</th>\n",
       "      <th>opn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authid                                               text    ext  \\\n",
       "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...  False   \n",
       "1  1997_605191.txt  Well, here we go with the stream of consciousn...  False   \n",
       "2  1997_687252.txt  An open keyboard and buttons to push. The thin...  False   \n",
       "3  1997_568848.txt  I can't believe it!  It's really happening!  M...   True   \n",
       "4  1997_688160.txt  Well, here I go with the good old stream of co...   True   \n",
       "\n",
       "     neu    agr    con    opn  \n",
       "0   True   True  False   True  \n",
       "1  False   True  False  False  \n",
       "2   True  False   True   True  \n",
       "3  False   True   True  False  \n",
       "4  False   True  False   True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LabelTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['ext'], X['neu'], X['agr'], X['con'], X['opn'] = [[True if x == 'y' else False for x in col] \\\n",
    "                                                                                         for col in [X['ext'],\n",
    "                                                                                                     X['neu'],\n",
    "                                                                                                     X['agr'],\n",
    "                                                                                                     X['con'], \n",
    "                                                                                                     X['opn']]]\n",
    "        return X\n",
    "    \n",
    "lbl_trnsfr = LabelTransformer()\n",
    "lbl_trnsfr.transform(essays.copy()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output above, the string labels got turned into boolean values (True, False).\n",
    "\n",
    "Next, we create a function to clean the `TEXT` /`text` column. This function turns all letters to lower case and removes some abbreviations that are common in the english language. It also removes special characters and multiple consecutive spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'well right now i just woke up from a mid day nap it sort of weird but ever since i moved to texas i have had problems concentrating on things i remember starting my homework in 10th grade as soon as the clock struck 4 and not stopping until it was done of course it was easier but i still did it but when i moved here the homework got a little more challenging and there was a lot more busy work and so i decided not to spend hours doing it and just getting by but the thing was that i always paid attention in class and just plain out knew the stuff and now that i look back if i had really worked hard and stayed on track the last two years without getting lazy i would have been a genius but hey that all good it too late to correct the past but i do not really know how to stay focused n the future the one thing i know is that when people say that because they live on campus they can not concentrate it b s for me it would be easier there but alas i am living at home under the watchful eye of my parents and a little nagging sister that just nags and nags and nags you get my point another thing is is that it just a hassle to have to go all the way back to school to just to go to library to study i need to move out but i do not know how to tell them do not get me wrong i see where they are coming from and why they do not want me to move out but i need to get away and be on my own they have sheltered me so much and i do not have a worry in the world the only thing that they ask me to do is keep my room clean and help out with the business once in a while but i can not even do that but i need to but i got enough money from ut to live at a dorm or apartment next semester and i think i will take advantage of that but off that topic now i went to sixth street last night and had a blast i have not been there in so long now i know why i love austin so much when i lived in va i used to go up to dc all the time and had a blast but here there are so many students running around at night i just want to have some fun and i know that i am responsible enough to be able to have fun but keep my priorities straight living at home i can not go out at all without them asking where with who why when are you coming back and all those questions i just wish i could be treated like a responsible person for once but my sister screwed that up for me she went crazy the second she moved into college and messed up her whole college career by partying too much and that the ultimate reason that they do not want me to go and have fun but i am not little anymore and they need to let me go and explore the world but i am indian with indian culture with indian values they go against having fun i mean in the sense of meeting people or going out with people or partying or just plain having fun my school is difficult already but somehow i think that having more freedom will put more pressure on me to do better in school because that what my parents and ultimately i expect of myself well it been fun writing i do not know if you go anything out of this writing but it helped me get some of my thoughts into order so i hope you had fun reading it and good luck ta'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"i’m\", \"i am \", text)\n",
    "    text = re.sub('b/c', 'because', text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"’ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "clean_text(essays_raw.TEXT[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we take a look at our sample essay now, it looks pretty good. Note that to make things simpler a string like `it's` is striped down to just `it`. We chose to do so because `is` is a typical stopword that we'll remove anyway.\n",
    "\n",
    "Now, we implement a class `TextCleaner` that applies the `clean_text` function to every row in the  `TEXT` / `text` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>well right now i just woke up from a mid day n...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>well here we go with the stream of consciousne...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>an open keyboard and buttons to push the thing...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>i can not believe it it really happening my pu...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>well here i go with the good old stream of con...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT cEXT  \\\n",
       "0  1997_504851.txt  well right now i just woke up from a mid day n...    n   \n",
       "1  1997_605191.txt  well here we go with the stream of consciousne...    n   \n",
       "2  1997_687252.txt  an open keyboard and buttons to push the thing...    n   \n",
       "3  1997_568848.txt  i can not believe it it really happening my pu...    y   \n",
       "4  1997_688160.txt  well here i go with the good old stream of con...    y   \n",
       "\n",
       "  cNEU cAGR cCON cOPN  \n",
       "0    y    y    n    y  \n",
       "1    n    y    n    n  \n",
       "2    y    n    y    y  \n",
       "3    n    y    y    n  \n",
       "4    n    y    n    y  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline test\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, txt_col):\n",
    "        self.txt_col = txt_col\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.txt_col] = X[self.txt_col].apply(clean_text)\n",
    "        return X\n",
    "\n",
    "cleaner = TextCleaner('TEXT')\n",
    "cleaner.transform(essays_raw.copy()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks alright. Our preprocessing classes seem to work fine. It's time to build a pipeline that combines the different preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Build and apply cleaning pipeline\n",
    "\n",
    "We create a pipeline that contains all preprocessing steps we defined early. We can pass the raw data to the apply to create a clean data set that is (almost) ready to be fed to an machine learning algorithm.\n",
    "\n",
    "Note that we'll create another pipeline later on (after we create a train-test split). This pipeline uses the class `TfidfVectorizer` from `sklearn` to tokenize the text data and compute tf-idf statistics. This class can also be used to remove stop words from text input. Stop words are words that occur very frequently and thus do not contain much information about the specific content of a text. The second pipeline also contains a modelling step (i.e. fitting some classifier).\n",
    "\n",
    "This seperation into two pipelines is neccessary because `TfidfVectorizer` alters the shape of the input data. Thus, in order to feed datasets of different sizes (i.e. the test set) into a trained model, vectorization should go hand in hand with the modelling step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ext</th>\n",
       "      <th>neu</th>\n",
       "      <th>agr</th>\n",
       "      <th>con</th>\n",
       "      <th>opn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well right now i just woke up from a mid day n...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well here we go with the stream of consciousne...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an open keyboard and buttons to push the thing...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i can not believe it it really happening my pu...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well here i go with the good old stream of con...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    ext    neu    agr  \\\n",
       "0  well right now i just woke up from a mid day n...  False   True   True   \n",
       "1  well here we go with the stream of consciousne...  False  False   True   \n",
       "2  an open keyboard and buttons to push the thing...  False   True  False   \n",
       "3  i can not believe it it really happening my pu...   True  False   True   \n",
       "4  well here i go with the good old stream of con...   True  False   True   \n",
       "\n",
       "     con    opn  \n",
       "0  False   True  \n",
       "1  False  False  \n",
       "2   True   True  \n",
       "3   True  False  \n",
       "4  False   True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New pipeline\n",
    "\n",
    "clean_pipeline = Pipeline([('colclean', ColNameCleaner()),\n",
    "                           ('idcoldrop', ColDropper(\"authid\")),\n",
    "                           ('lbltransf', LabelTransformer()),\n",
    "                           ('txtclean', TextCleaner('text'))])\n",
    "\n",
    "essays_clean = clean_pipeline.fit_transform(essays_raw.copy())\n",
    "essays_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Create a training set and a testing set\n",
    "\n",
    "We create a train test split from the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1726,)\n",
      "(741,)\n",
      "(1726, 5)\n",
      "(741, 5)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(essays_clean, random_state = 1, test_size = 0.3, shuffle = True)\n",
    "\n",
    "X_train = train['text'].copy()\n",
    "Y_train = train.copy().drop('text', axis = 1)\n",
    "\n",
    "X_test = test['text'].copy()\n",
    "Y_test = test.copy().drop('text', axis = 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Explore models\n",
    "\n",
    "In the next step we try out some common machine learning algorithms on the preprocessed training set and see which algorithms appear to be promising. We also choose the approach to fit a separate model for each label as done by previous work (e.g. Majumber et al., 2016). We write a function that computes tf-idf statistics for the `text` column and fits seperate model for each personality dimension. It also evalutes the model on the training set using the `accuracy` metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_clf(classifier, categories = ['ext', 'neu', 'agr', 'con', 'opn']):\n",
    "    \n",
    "    model_pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words = stop_words)),\n",
    "                               ('clf', classifier)])\n",
    "    \n",
    "    print('Accuracy using {}'.format(classifier))\n",
    "    \n",
    "    for category in categories:\n",
    "        model_pipeline.fit(X_train, Y_train[category])\n",
    "        preds = model_pipeline.predict(X_train)\n",
    "        print('Dimension {}: {}'.format(category, accuracy_score(Y_train[category], preds)))\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can easily apply this function to some algorithms we are interested in. By the way, as an alternative approach we could have used `sklearn`'s `MultiOuputClassifier` class to handle multi label classification (some algorithms support it by default, e.g. `KNeighborsClassifier`).\n",
    "\n",
    "Exmaple of training a classifier using the `MultiOutputClassifier`class:\n",
    "\n",
    "`forest_clf = MultiOutputClassifier(RandomForestClassifier(n_estimators = 20))`\n",
    "\n",
    "`forest_clf.fit(X_train_prepared, y_train_prepared)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Dimension ext: 0.8030127462340672\n",
      "Dimension neu: 0.9391657010428737\n",
      "Dimension agr: 0.5909617612977984\n",
      "Dimension con: 0.8962920046349943\n",
      "Dimension opn: 0.9235225955967555\n",
      "\n",
      "\n",
      "Accuracy using RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "Dimension ext: 1.0\n",
      "Dimension neu: 1.0\n",
      "Dimension agr: 1.0\n",
      "Dimension con: 1.0\n",
      "Dimension opn: 1.0\n",
      "\n",
      "\n",
      "Accuracy using LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Dimension ext: 0.929316338354577\n",
      "Dimension neu: 0.9269988412514485\n",
      "Dimension agr: 0.9078794901506373\n",
      "Dimension con: 0.9258400926998841\n",
      "Dimension opn: 0.8794901506373117\n",
      "\n",
      "\n",
      "None None None\n"
     ]
    }
   ],
   "source": [
    "classifiers = [MultinomialNB(fit_prior = True, class_prior = None),\n",
    "               RandomForestClassifier(n_estimators = 50, random_state = 42),\n",
    "               LogisticRegression(solver = 'sag')]\n",
    "\n",
    "nb_clf, forest_clf, log_clf = list((map(multi_label_clf, classifiers)))\n",
    "print(nb_clf, forest_clf, log_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model tuning\n",
    "The RandomForrestClassifer seems to do very well (perfect accuracy for all dimensions). The logistic regression perform good as well. So, we further explore these two model types.\n",
    "\n",
    "The perfect accuracy of the random forest model (accuracy scores of 1.0 for all five dimensions) indicates that the random forrest algorithm overfits the data. We don't want to touch our test set yet since we still need to fine-tune our model. To get a more realistic estimate on how the algorithm performs on new data we can use cross-validation.\n",
    "\n",
    "(Although the dataset is quite balanced we might want to take a look at metrics other than accuracy, as well - for example precision, recall and the F1-score.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_clf_cv(classifier, categories = ['ext', 'neu', 'agr', 'con', 'opn']):\n",
    "    \n",
    "    model_pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words = stop_words)),\n",
    "                               ('clf', classifier)])\n",
    "    \n",
    "    print('Accuracy using {}'.format(classifier))\n",
    "    \n",
    "    for category in categories:\n",
    "        model_pipeline.fit(X_train, Y_train[category])\n",
    "        scores = cross_val_score(model_pipeline, X_train, Y_train[category], scoring = \"accuracy\", cv = 3)\n",
    "        print(scores)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "[0.57465278 0.55478261 0.53913043]\n",
      "[0.54340278 0.54513889 0.54355401]\n",
      "[0.515625   0.5373913  0.57391304]\n",
      "[0.55381944 0.51130435 0.5426087 ]\n",
      "[0.59201389 0.59722222 0.61672474]\n",
      "\n",
      "\n",
      "Accuracy using LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "[0.56076389 0.56695652 0.59130435]\n",
      "[0.54513889 0.51736111 0.57839721]\n",
      "[0.54513889 0.54434783 0.54608696]\n",
      "[0.609375   0.53913043 0.53217391]\n",
      "[0.60416667 0.64756944 0.63763066]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_label_clf_cv(RandomForestClassifier(n_estimators = 50, random_state = 42))\n",
    "multi_label_clf_cv(LogisticRegression(solver = 'sag'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oof! When using cross validation the algorithms do not do as well as expected. The accuracy for most dimensions is barely above chance level (50%). Now, the logistic regression seems to do a little bit better compared the random forest. One thing we can do to optimize our model is tune its hyperparameters using grid search or randomized search.\n",
    "\n",
    "From now on we'll concentrate on the `LogisticRegression` classifiers since it seems to perform better on data it has not seen before.\n",
    "\n",
    "Remember that we actually fit one model per personality dimension. We will do a grid search for each model to find good hyperparameters. We'll only focus on some of the possbile hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_search(category):\n",
    "    log_reg_pipe = Pipeline([(\"tfidf\",  TfidfVectorizer(stop_words = stop_words)),\n",
    "                         ('clf', LogisticRegression())])\n",
    "\n",
    "    param_grid = {}\n",
    "    param_grid[\"clf__C\"] = np.logspace(-3, 3, 7)\n",
    "    param_grid[\"clf__solver\"] = [\"liblinear\", \"sag\"]\n",
    "\n",
    "    grid_search = GridSearchCV(log_reg_pipe, param_grid, cv = 3,\n",
    "                              scoring = 'accuracy')\n",
    "\n",
    "    grid_search.fit(X_train, Y_train[category])\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell might take a few minutes\n",
    "categories = ['ext', 'neu', 'agr', 'con', 'opn']\n",
    "\n",
    "best_ext_model, best_neu_model, best_agr_model,best_con_model, best_opn_model = list(map(log_reg_search, categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56076389 0.56695652 0.59130435]\n"
     ]
    }
   ],
   "source": [
    "# Example of a model validation using cross validation\n",
    "best_ext_model.fit(X_train, Y_train['ext'])\n",
    "scores = cross_val_score(best_ext_model, X_train, Y_train['ext'], scoring = \"accuracy\", cv = 3)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.546875   0.51736111 0.57665505]\n"
     ]
    }
   ],
   "source": [
    "# Example of a model validation using cross validation\n",
    "best_neu_model.fit(X_train, Y_train['neu'])\n",
    "scores = cross_val_score(best_ext_model, X_train, Y_train['neu'], scoring = \"accuracy\", cv = 3)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54513889 0.54434783 0.54956522]\n"
     ]
    }
   ],
   "source": [
    "# Example of a model validation using cross validation\n",
    "best_agr_model.fit(X_train, Y_train['agr'])\n",
    "scores = cross_val_score(best_ext_model, X_train, Y_train['agr'], scoring = \"accuracy\", cv = 3)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60590278 0.5426087  0.53391304]\n"
     ]
    }
   ],
   "source": [
    "# Example of a model validation using cross validation\n",
    "best_con_model.fit(X_train, Y_train['con'])\n",
    "scores = cross_val_score(best_ext_model, X_train, Y_train['con'], scoring = \"accuracy\", cv = 3)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60416667 0.65104167 0.63763066]\n"
     ]
    }
   ],
   "source": [
    "# Example of a model validation using cross validation\n",
    "best_opn_model.fit(X_train, Y_train['opn'])\n",
    "scores = cross_val_score(best_ext_model, X_train, Y_train['opn'], scoring = \"accuracy\", cv = 3)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate models using the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(category, model):\n",
    "    preds = model.predict(X_test)\n",
    "    preds = model.predict(X_test)\n",
    "    return accuracy_score(Y_test[category], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.553306342780027 0.5681511470985156 0.5425101214574899 0.5465587044534413 0.6140350877192983\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracy('ext', best_ext_model),\n",
    "      test_accuracy('neu', best_neu_model),\n",
    "      test_accuracy('agr', best_agr_model),\n",
    "      test_accuracy('con', best_con_model),\n",
    "      test_accuracy('opn', best_opn_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, at least all accuracy scores are above chance level. Personality detection from text is a hard. Even in the work of Majumber et al. (2016) (which compared a lot different deep learning and shallow machine learning models) 4 out of 5 models (per personality dimension) reached a mean accuracy of below 0.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "* Code / Struktur überarbeiten\n",
    "* Weitere mögliche Modelle explorieren, Grid Search optimieren\n",
    "* Mögliche Verbesserungen recherchieren\n",
    "* Das Modell auf andere Texte anwenden (z.B. Text von bekannten Persönlichkeiten - Donald Trump etc.)\n",
    "* word2vec und xgboost ausprobieren"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
